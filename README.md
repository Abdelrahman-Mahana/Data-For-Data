# 30-Day-of-Data-

## this is my learning journey to learn and understand more and more about Data
##### In this repo, I will write my daily habits of learning " problem solving, structure & algorithms, data science tools, computer vision, NLP , Machine learning & Deep learning "





**Day 1 of 30 Day of Data**
- Today I was excited to learn Object Detection using TensorFlow Object detection API, so I started studying it, This video was interesting to start with, it explains how to make [Real-Time Sign Language Detection with Tensorflow Object Detection](https://www.youtube.com/watch?v=pDXdlXlaCco) and Python | Deep Learning SSD ,so this is a good start for me to get an idea of TensorFlow Object detection API, after this video, I started installing TensorFlow Object detection API on my local computer, but I faced many bugs in the begging so if you try to install it take a deep breath and watch this video about how to [Install Tensorflow Object Detection From Scratch in 5 Steps](https://www.youtube.com/watch?v=dZh_ps8gKgs), and this is everything for today see you the next day 


**Day 2 of 30 Day of Data**
- today I started my step by step object detection project from scratch using TensorFlow object detection API and python, I create the repo and started describing how can you make it from installation to deployment, today I finished the following steps and I will continue in the following days  
                                   - Installation and Setup
                                   - Collecting Images Using Your Webcam or any device 
                                   - Labelling Images for Object Detection using LabelImg
you can see my [Tensorflow Object Detection From Scratch](https://github.com/Kareem-negm/Tensorflow-Object-Detection-From-Scratch) Repo and try making your model, if you face any issue or ideas feel free to make an issue or PR, and this is everything for today see you the next day 


**Day 3 of 30 Day of Data**

Today I was excited to learn and revision the basic command for windows CMD and the Git and GitHub command so I watch this video made by  Kunal Kushwaha for [Git and GitHub Tutorials](https://www.youtube.com/watch?v=apGV9Kg7ics) 

I learned the basic windows command like:

-- `ls` 

`mkdir`to make a file

`type nul > name.txt`to create an empty file 

`notepad name.txt` to open the file and write something 

`type name.txt`to show what is the file contain 

`del`to delet the file 

and all I need for Git 


I know Git well, but this was a good revision for me to restore my knowledge 
you can see the [Git and GitHub cheat sheet](https://github.com/Kareem-negm/30-Day-of-Data/tree/main/Git%20and%20GitHub%20cheat%20sheet) that has the best and basic commands for Git and GitHub , and this is everything for today see you the next day 


**Day 4 of 30 Day of Data**

Today I joined to the [LearnPlatform COVID-19 Impact on Digital Learning
](https://www.kaggle.com/c/learnplatform-covid19-impact-on-digital-learning) competition , I made my notebook and it has 9 upvotes in less than 24 hours my notebook named [COVID-19 Impact on Digital LearningðŸ’ªðŸ”¥ EDA
](https://www.kaggle.com/kareem3egm/covid-19-impact-on-digital-learning-eda/comments#1441291) 
I made some awesome analysis and visualization charts, it was a chance for me to review the most visualization libraries I know like Matplotlib and seaborn , and this is everything for today see you the next day 


**Day 5 of 30 Day of Data**

Today I fell in love with H20 AutoML, it's an unbelievable tool to make an efficient machine learning model with high accuracy and less than 15 lines of code 
I used it because today I joined to [Tabular Playground Series - Aug 2021
](https://www.kaggle.com/c/tabular-playground-series-aug-2021/code) competition and used a lot of Regression algorithms and the best one was XGboox and h2oautoml 
I advise you to learn more about it and you will get a high-efficiency model for your business , and this is everything for today see you the next day 


**Day 6 of 30 Day of Data**

It seems that the auto libraries is coming strongly,
today I learned about an auto visualization library that can make all of the visualizations you need in one single line of code

it's an awesome and very fixable library that you can use in your work, this [notebook](https://github.com/Kareem-negm/30-Day-of-Data/blob/main/automl-lazy-predict-training-30-classifiers.ipynb) contains three auto EDA libraries  that you can use in your daily work , and this is everything for today see you the next day 

**Day 7-8 of 30 Day of Data***

the auto tools have become very popular more than I know , for example, I learned in a few days more than 5 auto libraries for machine learning models, visualization, reports, and EDA 

today I will show you how can you used 3 liberties to report, EDA, and visualize your data automatedly using Auto libraries, the fires one is `pandas_profiling ` and you can use it to make a report, `sweetviz ` you can use it to make a good EDA, the last one is `autoviz` and you can use it to make a full data visualization 

you can find a notebook for these three libraries in my [Green Vehicle Guide auto EDA](https://www.kaggle.com/kareem3egm/green-vehicle-guide-auto-eda) notebook
 

